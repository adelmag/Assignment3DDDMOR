{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#Question (a):\n",
    "\n",
    "'''\n",
    "GILS implements the greedy iterated least squares price policy.\n",
    "The INPUTS are as follows:\n",
    "\n",
    "1) b_1, b_2, b_3, b_4 (floats): the bounds for the paramaters of the demand function, i.e.\n",
    "0 <= b_1 <= theta_1 <= b_2 AND b_3 <= theta_3 <= b_4 <= 0.\n",
    "\n",
    "2) min_p, max_p (floats): the bounds for the true price.\n",
    "\n",
    "3) t (int): time stamp.\n",
    "\n",
    "3) h (array of 2-tuples): the history of prices and demands up to time t. Namely:\n",
    "h = [(p_1,d_1); (p_2,d_2); . . . ; (p_t,d_t)].\n",
    "\n",
    "The OUTPUT is p_{t+1} (int), the price chosen by GILS for the next time stamp.\n",
    "'''\n",
    "\n",
    "def GILS(b_1, b_2, b_3, b_4, min_p, max_p, t, h):\n",
    "    \n",
    "    # Choose a random price for the first 2 time stamps.\n",
    "    if t == 0:\n",
    "        return random.uniform(min_p,max_p)\n",
    "    if t == 1:\n",
    "        p_1 = h[0][0]\n",
    "        p_2 = random.uniform(min_p,max_p)\n",
    "        while p_2 == p_1:\n",
    "            p_2 = random.uniform(min_p,max_p)\n",
    "        return p_2\n",
    "    \n",
    "    # If t>1, compute the least squares estimator (theta_1, theta_2).\n",
    "    # We use the usual solution for ls estimator in linear regression.\n",
    "    prices = [h[i][0] for i in range(t)]\n",
    "    demands = [h[i][1] for i in range(t)]\n",
    "    prod = [prices[i]*demands[i] for i in range(t)]\n",
    "    pric_squar = [prices[i]*prices[i] for i in range(t)]\n",
    "    \n",
    "    theta_2 = (sum(prod) - (sum(prices)*sum(demands))/t)/(sum(pric_squar) - sum(prices)*sum(prices)/t)\n",
    "    theta_1 = sum(demands)/t - theta_2*sum(prices)/t\n",
    "    \n",
    "    # Project them onto [b_1,b_2] x [b_3,b_4] if necessary\n",
    "    if theta_1 < b_1:\n",
    "        theta_1 = b_1\n",
    "    if theta_1 > b_2:\n",
    "        theta_1 = b_2\n",
    "    if theta_2 < b_3:\n",
    "        theta_2 = b_3\n",
    "    if theta_2 > b_4:\n",
    "        theta_2 = b_4\n",
    "    \n",
    "    # Return the perceived optimal price (assuming it will fall into [min_p, max_p])\n",
    "    return -theta_1/(2*theta_2)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Sign function determines the sign of a float.\n",
    "If the float is greater or equal than 0 the return equals 1,\n",
    "otherwise the return equals -1.\n",
    "\"\"\"\n",
    "\n",
    "def Sign(x):\n",
    "    if x >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "'''\n",
    "CILS implements the constrained iterated least squares price policy. The INPUTS are\n",
    "the same as for GILS with the threshold paramter K (float) added. OUTPUT is also p_{t+1}\n",
    "'''\n",
    "\n",
    "def CILS(b_1, b_2, b_3, b_4, min_p, max_p, t, h, K):\n",
    "    \n",
    "    #  Calculate the unconstrained price. \n",
    "    U_price = GILS(b_1, b_2, b_3, b_4, min_p, max_p, t, h)\n",
    "    \n",
    "    # Calculate the average of the prices up till time t\n",
    "    A_price = 0\n",
    "    if t > 0:\n",
    "        for history in h:\n",
    "            A_price += history[0]/(t)\n",
    "    \n",
    "    # Calculate  delta_t\n",
    "    delta_t = U_price  - A_price\n",
    "    \n",
    "    # Calculate the constrained price\n",
    "    if abs(delta_t) < K*((t+1)**(-1/4)):\n",
    "        return A_price + Sign(delta_t)*K*((t+1)**(-1/4))\n",
    "    else:\n",
    "        return U_price\n",
    "\n",
    "'''\n",
    "Let us assume for now that b_1 = 0.01, b_2 = 1000, b_3 = -500, b_4 = -0.01, min_p = 0, max_p = 100.\n",
    "And also that the true theta_1 = 10 and theta_2 = -0.5 so that D = 10 - 0.5*p.\n",
    "'''\n",
    "    \n",
    "#Questions (b) and (c):\n",
    "\n",
    "'''\n",
    "REGRET_fixed_K(K, T, theta_1, theta_2) computes all the regrets for CILS(K) up to time T for \n",
    "true paramters theta_1, theta_2 fixed, and parameter K. \n",
    "'''\n",
    "\n",
    "def REGRET_fixed_K(K, T, theta_1, theta_2):\n",
    "    best_p = -theta_1/(2*theta_2) # the best price in hindsight\n",
    "    regrets =[]\n",
    "    h = []\n",
    "    regret = 0\n",
    "    for t in range(T):\n",
    "        e_t = np.random.normal(0,1) # We assume the epsilon error at time t to be N(0,1) distributed.\n",
    "        p_t = CILS(0.01,1000,-500,-0.01,0,30, t, h, K)\n",
    "        d_t = theta_1 + theta_2*p_t +e_t\n",
    "        regret += best_p*(theta_1 + theta_2*best_p) - p_t*(d_t-e_t)\n",
    "        h.append((p_t,d_t))\n",
    "        regrets.append(regret)\n",
    "    return regrets\n",
    "\n",
    "'''\n",
    "REGRET_fixed_K(K, T, theta_1, theta_2) computes all the regrets at time T of all CILS(k) for k = 0 to 100. \n",
    "True paramters of the demand function are theta_1, theta_2. \n",
    "'''\n",
    "\n",
    "def REGRET_fixed_T(K, T, theta_1, theta_2):\n",
    "    regrets = []\n",
    "    for k in range(K):\n",
    "        temp = REGRET_fixed_K(k,T,theta_1,theta_2)\n",
    "        regrets.append(temp[T-1]) \n",
    "    return regrets\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # Question (b)\n",
    "    \n",
    "    '''\n",
    "    We compute the regret of CILS(0) for T = 1 to T = 1000. We then plot it against time \n",
    "    to assess its linear behavior.\n",
    "    '''\n",
    "    # Computation.\n",
    "    time_max = 1000\n",
    "    time = [t+1 for t in range(time_max)]\n",
    "    regrets = []\n",
    "    regrets = REGRET_fixed_K(0, time_max, 10, -0.5)\n",
    "    \n",
    "    # PLOT.\n",
    "    fig = plt.figure()\n",
    "    axes = fig.add_subplot(111)\n",
    "    axes.plot(time,regrets)\n",
    "    plt.show()\n",
    "    \n",
    "    # Question (c)\n",
    "   \n",
    "    # First approach\n",
    "    \n",
    "    \"\"\"\n",
    "    '''\n",
    "    Let's do a first approach where we fix T at 3 values, say T = 10, T = 100 and T = 1000.\n",
    "    and we compute regret at time T of CILS(k) for k = 0 to k_max - 1.\n",
    "    '''\n",
    "    \n",
    "    k_max = 100\n",
    "    parameters = [i for i in range(k_max)]\n",
    "    \n",
    "    # T = 10\n",
    "    regrets = REGRET_fixed_T(k_max, 10, 10, -0.5)\n",
    "    fig2 = plt.figure()\n",
    "    axes = fig2.add_subplot(111)\n",
    "    axes.plot(parameters,regrets)\n",
    "    plt.show()\n",
    "    \n",
    "    # T = 100\n",
    "    regrets = REGRET_fixed_T(k_max, 100, 10, -0.5)\n",
    "    fig3 = plt.figure()\n",
    "    axes = fig3.add_subplot(111)\n",
    "    axes.plot(parameters,regrets)\n",
    "    plt.show()\n",
    "    \n",
    "    # T = 1000\n",
    "    regrets = REGRET_fixed_T(k_max, 1000, 10, -0.5)\n",
    "    fig4 = plt.figure()\n",
    "    axes = fig4.add_subplot(111)\n",
    "    axes.plot(parameters,regrets)\n",
    "    plt.show()\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    '''\n",
    "    It seems that small values of K are always much better than large values of K, but maybe that is because\n",
    "    T is not large enough to see a significant difference. We try a second approach.\n",
    "    '''\n",
    "    \n",
    "    #Second approach\n",
    "    \n",
    "    '''\n",
    "    We compare the behavior of the regrets of CILS(k) for a smaller range of k.\n",
    "    We then plot each regret function against time on the same graph to compare their asymptotic behavior,\n",
    "    and determine for which CILS(k) is better for values of T.\n",
    "    '''\n",
    "    \n",
    "    k_max = 10 # Computing for k = 0, 1, ..., 9\n",
    "    time_max = 10000\n",
    "    time = [t+1 for t in range(time_max)]\n",
    "    regrets_k = []\n",
    "    for k in range(k_max):\n",
    "        regrets_k.append(REGRET_fixed_K(k, time_max, 10, -0.5)) \n",
    "        \n",
    "    # PLOT.\n",
    "    figx = plt.figure()\n",
    "    axes = figx.add_subplot(111)\n",
    "    \n",
    "\n",
    "    for k in range(k_max):\n",
    "        axes.plot(time,regrets_k[k],label = \"K = \" + str(k))\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Question b\n",
    " We see that for $\\kappa =0$ we indeed have linear regret except for very small T. \n",
    " This is because the first two prices are chosen randomly because there is no data yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question c\n",
    "In our plot we see the larger $\\kappa$ is the larger the regret is. \n",
    "However we do note that for larger $\\kappa$ the regret function behaves more like $\\sqrt T \\log(T)$ whereas for small $\\kappa$ we get more linear regret. Hence we expect that asympotitically large $\\kappa$ will result in less regret compared to smaller $\\kappa$. The reason for this is if $\\kappa$ is large we are forced to spend more time on learning: we try prices that may in the first place seem less optimal. If we do this the probability of getting stuck at an incorrect value of the optimal price becomes smaller and we therefore also have less regret in the asymptotic case. Note that in our plot however $T$ is too small to see the asympotic case. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
